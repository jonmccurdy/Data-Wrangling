videos_statistics <- bind_rows(stats_list)
videos |> inner_join(videos_statistics) |> select(-video_id) |> arrange(desc(as.numeric(views)))
stats_list
video_ids <- videos$video_id
video_ids
length(video_ids )
video_ids <- videos$video_id
stats_list <- list()
for(i in 1:length(video_ids)){
url_stats <- paste0(
"https://www.googleapis.com/youtube/v3/videos?part=statistics&id=",
video_ids[i], "&key=", youtube_api
)
res_stats <- fromJSON(content(GET(url_stats), "text", encoding = "UTF-8"))
stats_list[[i]] <- data.frame(video_id = res_stats$items$id, views=res_stats$items$statistics$viewCount)
}
videos_statistics <- bind_rows(stats_list)
videos |> inner_join(videos_statistics) |> select(-video_id) |> arrange(desc(as.numeric(views)))
videos |> inner_join(videos_statistics) |> select(-video_id) |> arrange(desc(as.numeric(views)))
videos |> inner_join(videos_statistics) |> select(-video_id) |> arrange(desc(as.numeric(views))) |> head(5)
videos |> inner_join(videos_statistics) |> select(-video_id) |> arrange(desc(as.numeric(views))) |> tail(5)
videos |> inner_join(videos_statistics) |> select(-video_id) |> arrange(as.numeric(views)) |> head(5)
videos |> inner_join(videos_statistics) |> select(-video_id) |> arrange(desc(as.numeric(views))) |> head(5)
videos |> inner_join(videos_statistics) |> select(-video_id) |> arrange(as.numeric(views)) |> head(5)
videos |> inner_join(videos_statistics) |> select(-video_id) |> arrange(desc(as.numeric(views))) |> head(5)
videos
v <- videos |> inner_join(videos_statistics) |> select(-video_id)
v
endpoint <- "https://api.millercenter.org/speeches"
# first request (start of pagination)
res <- POST(endpoint)
data <- fromJSON(content(res, "text", encoding = "UTF-8"))
# store first batch
all_speeches <- data$Items
all_speeches
all_speeches$president
all_speeches$title
library(httr)
library(jsonlite)
library(dplyr)
api_key <- "3865e89ec5be4607acac62b1fcc9618e"
url <- paste0(
"https://newsapi.org/v2/everything?",
"qInTitle=", URLencode("Josh Allen"), "&",
"from=2025-09-07&",
"language=en&",
"sortBy=popularity&",
"pageSize=100&",
"page=1&",
"apiKey=", api_key
)
url
response <- GET(url)
response
data <- content(reponse, as="text", encoding="UTF-8") |> fromJSON()
data <- content(response, as="text", encoding="UTF-8") |> fromJSON()
head(data$articles$title)
data$status
data$totalResults
data$articles$author
strsplit(data$articles$author, sep=" ")
?strsplit
strsplit(data$articles$author, split=" ")
authors <- strsplit(data$articles$author, split=" ")
unlist(authors)
episode_id
episode_id <- c("356", "$68", "478", "347", "136", "369")
episode_id[1]
episode_id[2]
episode_id[3]
for(i in 1:length(episode_id)){
print(episode_id[i])
}
(3 + 2)/3 - 2^(2 + 1)
(3 + 2)/3 - 2^(2 + 1) + 6*2
(3 + 2)/3 - 2^(2 + 1) + 6*1.5
(3 - 2)/3 - 2^(2 + 1) + 6*1.5
(3 - 2)/4 - 2^(2 + 1) + 6*1.5
(3 - 2)/4 - 2^(2 + 1) + 6
(3 - 2)/4 - 2^(2 + 1) + 6*2
(3 - 2)/4 - 2^(2 + 1) + 6*1.75
rep(c("ABC", "123", "Do-Re-Mi"), each=3)
rep(c("ABC", "123", "Do-Re-Mi"), times=3)
gc()
# Mount Programming Club: Monday at 5pm on Monday in this classroom
# SmallTalk on Wednesday at 4pm in Laughlin- more details to come
30*3.5333
106/36
mean(c(8,3,6,2,2,-1))
sd(c(8,3,6,2,2,-1))
median(c(8,3,6,2,2,-1))
library(tidyr)
library(dplyr)
library(RSQLite)
library(Lahman)
db_con <- dbConnect(RSQLite::SQLite(), "Lahman.db")
dbWriteTable(db_con, "People", People, overwrite=TRUE)
dbWriteTable(db_con, "Batting", Batting, overwrite=TRUE)
dbWriteTable(db_con, "Pitching", Pitching, overwrite=TRUE)
dbWriteTable(db_con, "Fielding", Fielding, overwrite=TRUE)
dbWriteTable(db_con, "Salaries", Salaries, overwrite=TRUE)
dbWriteTable(db_con, "Teams", Teams, overwrite=TRUE)
dbWriteTable(db_con, "TeamsFranchises", TeamsFranchises, overwrite=TRUE)
dbWriteTable(db_con, "Schools", Schools, overwrite=TRUE)
dbWriteTable(db_con, "HallOfFame", HallOfFame, overwrite=TRUE)
dbWriteTable(db_con, "CollegePlaying", CollegePlaying, overwrite=TRUE)
dbListTables(db_con)
tbl(db_con, "People") |> filter(birthMonth == 4, birthDay == 25) |>
select(playerID, nameFirst, nameLast, birthYear, birthMonth, birthDay) |>
arrange(desc(birthYear)) |> head(5)
tbl(db_con, "People") |> group_by(playerID) |>
inner_join(tbl(db_con, "Batting"), by="playerID") |>
group_by(playerID, nameFirst, nameLast) |> summarise(RBI_sum = sum(RBI)) |>
arrange(desc(RBI_sum)) |>
head(10)
#Most
tbl(db_con, "Teams") |> inner_join(tbl(db_con, "TeamsFranchises"), by="franchID") |>  select(teamID, W, franchName) |> group_by(teamID, franchName) |> summarise(Wins = sum(W)) |> arrange(desc(Wins)) |> head(5)
#Least
tbl(db_con, "Teams") |> inner_join(tbl(db_con, "TeamsFranchises"), by="franchID") |> select(teamID, W, franchName) |> group_by(teamID, franchName) |> summarise(Wins = sum(W)) |> arrange(Wins) |> head(5)
tbl(db_con, "People") |> inner_join(tbl(db_con, "CollegePlaying"), by="playerID") |> inner_join(tbl(db_con, "Schools"), by="schoolID") |> filter(name_full == "Mount St. Mary's University") |> group_by(nameFirst,nameLast,name_full) |> summarise(college_debut = min(yearID)) |> arrange(nameLast)
tbl(db_con, "Fielding") |> group_by(playerID) |> summarise(Total_G = sum(G), POS) |> inner_join(tbl(db_con, "People"), by="playerID") |> inner_join(tbl(db_con, "HallOfFame"), by="playerID") |> filter(POS != "P") |> filter(inducted == "Y", category == "Player") |> select(playerID, Total_G, POS, nameFirst, nameLast, inducted, category) |> arrange(Total_G)
tbl(db_con, "salaries") |> filter(yearID >= 2000) |> group_by(yearID, teamID) |> summarise(total_salary = sum(salary)) |> select(yearID, teamID, total_salary) |> group_by(yearID) |> slice_max(total_salary,n=1) |> inner_join(tbl(db_con,"Teams"), by=c("teamID","yearID")) |> select(yearID, teamID, total_salary, W, L)
tbl(db_con, "Batting") |> filter(HR > 30)|> inner_join(tbl(db_con, "People"), by="playerID") |> group_by(playerID, nameFirst, nameLast) |> summarise(seasons_over_30_HR = n()) |> arrange(desc(seasons_over_30_HR))
tbl(db_con, "Batting") |> filter(AB>200) |> group_by(playerID) |> summarise(qualified_seasons = n(), total_H = sum(H, na.rm=TRUE), total_AB = sum(AB, na.rm=TRUE)) |> mutate(average = 1.0 * total_H / total_AB, category = cut(qualified_seasons, breaks = c(0,5,10,15,Inf), labels = c("0-5seasons","6-10seasons","11-15seasons","16+seasons"), right=TRUE)) |> group_by(category) |> summarise(average = mean(average,na.rm=TRUE), n_players = n(), sum(total_H), sum(total_AB)) |> arrange(category) ##Used AI to help with this
tbl(db_con, "Pitching") |> select(yearID, CG) |> filter(!is.na(CG)) |> collect() |> mutate(decade = cut(yearID, breaks = seq(1870, 2030, by = 10), labels = paste0(seq(1870, 2020, by = 10), "s"), right=FALSE)) |> group_by(decade) |> summarise(total_complete_games = sum(CG, na.rm=TRUE)) |> arrange(decade) #Used AI for this problem - To help with understanding cut() and paste0()
knitr::opts_chunk$set(echo = TRUE)
library(DBI)
library(RSQLite)
library(dplyr)
library(Lahman)
db_con <- dbConnect(RSQLite::SQLite(), "Lahman.db")
dbWriteTable(db_con, "People", People, overwrite = TRUE)
dbWriteTable(db_con, "Batting", Batting, overwrite = TRUE)
dbWriteTable(db_con, "Pitching", Pitching, overwrite = TRUE)
dbWriteTable(db_con, "Fielding", Fielding, overwrite = TRUE)
dbWriteTable(db_con, "Salaries", Salaries, overwrite = TRUE)
dbWriteTable(db_con, "Schools", Schools, overwrite = TRUE)
dbWriteTable(db_con, "Teams", Teams, overwrite = TRUE)
dbWriteTable(db_con, "HallOfFame", HallOfFame, overwrite = TRUE)
dbWriteTable(db_con, "TeamsFranchises", TeamsFranchises, overwrite = TRUE)
dbWriteTable(db_con, "CollegePlaying", CollegePlaying, overwrite = TRUE)
tbl(db_con, "People") |>
filter(birthMonth == 11, birthDay == 25) |>
select(nameFirst, nameLast, birthYear, birthMonth, birthDay) |>
arrange(desc(birthYear)) |>
head(5)
tbl(db_con, "Batting") |>
select(playerID, RBI) |>
group_by(playerID) |>
summarise(RBI = sum(RBI)) |>
inner_join(tbl(db_con, "People"), by=c("playerID" = "playerID")) |>
select(playerID, nameFirst, nameLast, RBI)|>
arrange(desc(RBI)) |>
head(10)
tbl(db_con, "Teams") |>
select(franchID, W, yearID) |>
inner_join(tbl(db_con, "TeamsFranchises"), by=c("franchID" = "franchID")) |>
select(franchID, franchName, W) |>
group_by(franchID) |>
arrange(desc(W))
tbl(db_con, "Teams") |>
select(franchID, W, yearID) |>
inner_join(tbl(db_con, "TeamsFranchises"), by=c("franchID" = "franchID")) |>
select(franchID, franchName, W) |>
group_by(franchID) |>
arrange(W)
tbl(db_con, "People") |>
inner_join(tbl(db_con, "CollegePlaying"), by=c("playerID" = "playerID")) |>
inner_join(tbl(db_con, "Schools"), by = c("schoolID" = "schoolID")) |>
select(nameFirst, nameLast, name_full) |>
filter(name_full == "Mount St. Mary's University") |>
distinct()
tbl(db_con, "Fielding") |>
group_by(playerID) |>
summarise(Total_G = sum(G)) |>
inner_join(tbl(db_con, "People"), by=c("playerID" = "playerID")) |>
inner_join(tbl(db_con, "HallOfFame"), by=c("playerID" = "playerID")) |>
inner_join(tbl(db_con, "Fielding"), by = c("playerID" = "playerID")) |>
select(playerID, Total_G, POS, nameFirst, nameLast, inducted, category) |>
filter(POS != "P") |>
filter(inducted == "Y") |>
filter(category == "Player") |>
arrange(Total_G) |>
distinct()
tbl(db_con, "Batting") |>
filter(HR > 30) |>
group_by(playerID) |>
summarise(seasons_over_30_hr = n()) |>
inner_join(tbl(db_con, "Batting"), by=c("playerID" = "playerID")) |>
inner_join(tbl(db_con, "People"), by=c("playerID" = "playerID")) |>
select(playerID, nameFirst, nameLast, seasons_over_30_hr) |>
distinct() |>
arrange(desc(seasons_over_30_hr))
knitr::opts_chunk$set(echo = TRUE)
library(DBI)
library(RSQLite)
library(dbplyr)
library(dplyr)
library(nycflights13)
db_con_Lahman <- dbConnect(RSQLite ::SQLite(), "/Users/akarshgaonkar/Documents/Fall_2025/DATA_330/Lahman.db")
dbWriteTable(db_con_Lahman, "People",People ,overwrite = TRUE)
tbl(db_con,"People") %>%
select(nameFirst, nameLast, birthYear, birthMonth, birthDay) %>%
filter(birthMonth == 9 & birthDay == 9) %>%
arrange(desc(birthYear)) %>%
head(5)
tbl(db_con,"Batting") %>%
select(playerID, RBI) %>%
group_by(playerID) %>% summarize(RBI = sum(RBI))%>%
inner_join(tbl(db_con, "People"), by = "playerID")%>%
select(nameFirst, nameLast, RBI) %>%
arrange(desc(RBI))
tbl(db_con,"Teams") %>%
select(W,L,franchID) %>%
group_by(franchID) %>%
summarize(win_total = sum(W)) %>%
inner_join(tbl(db_con, "TeamsFranchise"),
by = "franchID") %>%
select(franchID, win_total, franchName) %>%
arrange(desc(win_total)) %>%
head(5)
tbl(db_con,"Teams") %>%
select(W,L,franchID) %>%
group_by(franchID) %>%
summarize(win_total = sum(W)) %>%
inner_join(tbl(db_con, "TeamsFranchise"),
by = "franchID") %>%
select(franchID, win_total, franchName) %>%
arrange(win_total) %>%
head(5)
tbl(db_con,"CollegePlaying") %>%
filter(schoolID == "mtstmarys") %>%
inner_join(tbl(db_con,"people"),
by = "playerID") %>%
select(playerID, schoolID, yearID, nameFirst, nameLast) %>%
inner_join(tbl(db_con, "Schools"),
by = "schoolID") %>%
select(nameFirst, nameLast, name_full, yearID) %>%
group_by(nameLast, nameFirst, name_full) %>%
summarize(debut_year = min(yearID))
tbl(db_con,"Fielding") %>%
filter(POS != "P") %>%
group_by(playerID) %>%
summarize(games_played = sum(G)) %>%
inner_join(tbl(db_con, "HallOfFame"),
by = "playerID") %>%
filter(inducted == "Y") %>%
inner_join(tbl(db_con,"People"),
by = "playerID")%>%
filter(category == "Player") %>%
select(playerID, games_played, nameFirst, nameLast, inducted,
category) %>%
arrange(games_played)
tbl(db_con,"Salaries") %>%
group_by(teamID, yearID) %>%
summarize(total_pay = sum(salary)) %>%
arrange(desc(total_pay)) %>%
group_by(yearID) %>%
slice_max(total_pay)%>%
filter(yearID >= 2000) %>%
inner_join(tbl(db_con, "Teams"),
by = c("teamID","yearID" )) %>%
select(yearID, teamID, total_pay, W, L) %>%
arrange(W) %>%
head(5)
tbl(db_con,"Batting") %>%
filter(HR >=30) %>%
group_by(playerID) %>%
summarize(seasons_over_30HR = n()) %>%
inner_join(tbl(db_con, "People"), by = "playerID") %>%
select(playerID, nameFirst, nameLast, seasons_over_30HR) %>%
arrange(desc(seasons_over_30HR))
tbl(db_con,"Batting") %>%
filter(AB>200) %>%
group_by(playerID) %>%
summarize(seasons_played = n(), total_AB = sum(AB), total_H =sum(H))%>%
mutate(category = cut(seasons_played, breaks = c(0,5.5,10.5,15.5,150),
labels = c("0-5 seasons", "6-10 seasons", "11-15 seasons",
"16+seasons"))) %>%
group_by(category) %>% summarize(n_players = n(),
total_AB = sum(total_AB),
total_H = sum(total_H)) %>%
mutate(average = 1.0*total_H/total_AB) %>%
arrange(desc(n_players))
step1 <- tbl(db_con,"Pitching") %>%
filter(CG != 0) %>%
group_by(playerID, yearID) %>%
summarize(CG = sum(CG))
step1_new <- data.frame(step1)
years <- step1_new$yearID
years_decade <- (years%/%10)*10
step1_new <- cbind(step1_new,years_decade)
step1_new %>%
group_by(years_decade) %>%
summarise(CG = sum(CG))
url <- "http://api.worldbank.org/v2/country/US/indicator/NY.GDP.MKTP.CD?format=xml"
xml_doc <- read_xml(url)
library(httr)
url <- "http://api.worldbank.org/v2/country/US/indicator/NY.GDP.MKTP.CD?format=xml"
xml_doc <- read_xml(url)
library(xml2)
url <- "http://api.worldbank.org/v2/country/US/indicator/NY.GDP.MKTP.CD?format=xml"
xml_doc <- read_xml(url)
# 2. Find all <data> entries
records <- xml_find_all(xml_doc, "//wb:data",
ns = xml_ns(xml_doc))
# 3. Extract year
years <- xml_text(xml_find_all(xml_doc, "//wb:date", ns = xml_ns(xml_doc)))
# 4. Extract GDP value
gdp_values <- xml_text(xml_find_all(xml_doc, "//wb:value", ns = xml_ns(xml_doc)))
# 5. Put into data frame
df <- data.frame(
year = years,
gdp = as.numeric(gdp_values)
)
head(df)
xml_doc
xml_doc[1]
xml_doc$doc
xml_doc$node
xml_find_all(xml_doc, "//wb:data", ns = xml_ns(xml_doc))
library(xml2)
xml_data <- read_xml('
<bookstore>
<book id="b1">
<title>R for Data Science</title>
<author>Hadley Wickham</author>
<price currency="USD">39.99</price>
</book>
<book id="b2">
<title>Advanced R</title>
<author>Hadley Wickham</author>
<price currency="USD">49.99</price>
</book>
</bookstore>
')
xml_find_all(xml_data, "//book")
xml_find_all(xml_data, "//bookstore")
xml_find_all(xml_data, "//bookstore")[1]
xml_find_all(xml_data, "//book")
xml_text(xml_find_all(xml_data, "//title"))
xml_text(xml_data, "//book")
xml_text(xml_find_all(xml_data, "//author"))
xml_text(xml_find_all(xml_data, "//price"))
xml_text(xml_find_all(xml_data, "price"))
xml_text(xml_find_all(xml_data, "//price"))
xml_attr(xml_find_all(xml_data, "//price"), "currency")
xml_find_all(xml_data, "//price")
xml_attr(xml_find_all(xml_data, "//book"), "id")
?xml_find_all
xml_find_all(xml_data, "//book")
xml_find_all(xml_data, "//title")
xml_find_all(xml_data, "//book")
xml_find_all(xml_data, "//title")
xml_find_all(xml_data, "//author")
xml_find_all(xml_data, "//price")
xml_text(xml_find_all(xml_data, "//title"))
class(xml_find_all(xml_data, "//price"))
xml_text(xml_find_all(xml_data, "//title"))
titles <- xml_text(xml_find_all(xml_data, "//title"))
titles
authors <- xml_text(xml_find_all(xml_data, "//author"))
authors
prices <- xml_text(xml_find_all(xml_data, "//price"))
price
titles <- xml_text(xml_find_all(xml_data, "//title"))
titles
authors <- xml_text(xml_find_all(xml_data, "//author"))
authors
prices <- xml_text(xml_find_all(xml_data, "//price"))
prices
currencies <- xml_attr(xml_find_all(xml_data, "//price"), "currency")
currencies
# Combine into a data frame
df <- data.frame(title = titles, author = authors, price = as.numeric(prices), currency = currencies)
df
library(xml2)
# 1. Read XML directly from a URL
url <- "http://api.worldbank.org/v2/country/US/indicator/NY.GDP.MKTP.CD?format=xml"
xml_doc <- read_xml(url)
# 2. Find all <data> entries
records <- xml_find_all(xml_doc, "//wb:data",
ns = xml_ns(xml_doc))
# 3. Extract year
years <- xml_text(xml_find_all(xml_doc, "//wb:date", ns = xml_ns(xml_doc)))
# 4. Extract GDP value
gdp_values <- xml_text(xml_find_all(xml_doc, "//wb:value", ns = xml_ns(xml_doc)))
# 5. Put into data frame
df <- data.frame(
year = years,
gdp = as.numeric(gdp_values)
)
head(df)
dim(df)
GET(base_url, query = list(format = "xml", page = 1))
base_url <- "http://api.worldbank.org/v2/country/US/indicator/NY.GDP.MKTP.CD"
GET(base_url, query = list(format = "xml", page = 1))
GET(base_url, query = list(format = "xml", page = 2))
#| warning: false
library(xml2)
library(httr)
xml_data <- read_xml('
<bookstore>
<book id="b1">
<title>R for Data Science</title>
<author>Hadley Wickham</author>
<price currency="USD">39.99</price>
</book>
<book id="b2">
<title>Advanced R</title>
<author>Hadley Wickham</author>
<price currency="USD">49.99</price>
</book>
</bookstore>
')
url <- "http://api.worldbank.org/v2/country/US/indicator/NY.GDP.MKTP.CD?format=xml"
xml_doc <- read_xml(url)
xml_find_all(xml_doc, "//wb:data",
ns = xml_ns(xml_doc))
xml_find_all(xml_doc, "//wb:data",
ns = xml_ns(xml_doc))[1]
xml_text(xml_find_all(xml_doc, "//wb:data",
ns = xml_ns(xml_doc))[1])
xml_text(xml_find_all(xml_doc, "//wb:data"))
xml_find_all(xml_doc, "//wb:data")
xml_find_all(xml_doc, "//wb:data")[1]
xml_text(xml_find_all(xml_doc, "//wb:data")[1])
xml_attrs(xml_find_all(xml_doc, "//wb:data")[1])
res1 <- GET(url, query = list(format = "xml", page = 1))
res1
xml1 <-  read_xml(content(res1, "text"))
xml1 <-  read_xml(content(res1, "text", encoding = UTF-8))
xml1 <-  read_xml(content(res1, "text", encoding = "UTF-8"))
xml1
head(xml1)
xml1[1]
xml1[2]
xml1[[1]]
xml_text(xml1[1])
xml_attr(xml_find_all(xml1, "//wb:data")[1])
xml_find_all(xml1, "//wb:data")
xml_find_all(xml2, "//wb:data")
res1 <- GET(url, query = list(format = "xml", page = 1))
xml1 <-  read_xml(content(res1, "text", encoding = "UTF-8"))
res2 <- GET(url, query = list(format = "xml", page = 2))
xml2 <-  read_xml(content(res2, "text", encoding = "UTF-8"))
xml_attr(xml_find_all(xml1, "//wb:data"))
xml_attrs(xml_find_all(xml1, "//wb:data"))
xml_attrs(xml_find_all(xml2, "//wb:data"))
head(gdp_data)
res1 <- GET(url, query = list(format = "xml", page = 1))
xml1 <-  read_xml(content(res1, "text", encoding = "UTF-8"))
res2 <- GET(url, query = list(format = "xml", page = 2))
xml2 <-  read_xml(content(res2, "text", encoding = "UTF-8"))
years1 <- xml_text(xml_find_all(xml1, "//wb:date"))
values1 <- xml_text(xml_find_all(xml1, "//wb:value"))
df1 <- data.frame(
year = as.integer(years1),
gdp_usd = as.numeric(values1)
)
years2 <- xml_text(xml_find_all(xml2, "//wb:date"))
values2 <- xml_text(xml_find_all(xml2, "//wb:value"))
df2 <- data.frame(
year = as.integer(years2),
gdp_usd = as.numeric(values2)
)
gdp_data <- rbind(df1, df2)
gdp_data <- gdp_data[order(gdp_data$year), ]
head(gdp_data)
tail(gdp_data)
gdp_data
res1 <- GET(url, query = list(format = "xml", page = 1))
xml1 <-  read_xml(content(res1, "text", encoding = "UTF-8"))
res2 <- GET(url, query = list(format = "xml", page = 2))
xml2 <-  read_xml(content(res2, "text", encoding = "UTF-8"))
years1 <- xml_text(xml_find_all(xml1, "//wb:date"))
values1 <- xml_text(xml_find_all(xml1, "//wb:value"))
df1 <- data.frame(
year = as.integer(years1),
gdp_usd = as.numeric(values1)
)
years2 <- xml_text(xml_find_all(xml2, "//wb:date"))
values2 <- xml_text(xml_find_all(xml2, "//wb:value"))
df2 <- data.frame(
year = as.integer(years2),
gdp_usd = as.numeric(values2)
)
gdp_data <- rbind(df1, df2)
head(gdp_data)
dim(gdp_data)
gdp_data
url <- "http://api.worldbank.org/v2/country/US/indicator/NY.GDP.MKTP.CD?format=xml"
xml_doc <- read_xml(url)
xml_attr(xml_find_all(xml_doc, "//wb:data")[1])
currencies <- xml_attr(xml_find_all(xml_data, "//price"), "currency")
currencies
xml_attr(xml_find_all(xml_doc, "//wb:data"))
url <- "http://api.worldbank.org/v2/country/US/indicator/NY.GDP.MKTP.CD?format=xml"
xml_doc <- read_xml(url)
xml_attrs(xml_find_all(xml_doc, "//wb:data")[1])
xml_doc <- read_xml(url)
xml_attrs(xml_find_all(xml_doc, "//wb:data"))
xml_doc <- read_xml(url)
xml_attrs(xml_find_all(xml_doc, "//wb:data")[1])
plot(gdp_data)
lines(gdp_data)
lines(gdp_data)
plot(gdp_data)
xml_find_all(xml_data, "//book")
xml_find_all(xml_data, "//title")
xml_find_all(xml_data, "//author")
xml_find_all(xml_data, "//price")
